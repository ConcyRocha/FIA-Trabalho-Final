{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e6553dd0-50b2-41d2-9197-89143fe18461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import ltn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a97192-407b-45c2-afba-1bc598037e52",
   "metadata": {},
   "source": [
    "### Código para Gerar o Dataset\n",
    "\n",
    "Este código cria a classe CLEVR_Generator e gera os vetores exatamente no formato [x, y, r, g, b, s]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6868c402-1056-453e-97ba-06aee6d4de20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset gerado. Shape: torch.Size([150, 11])\n",
      "Exemplo: Small Red Triangle at (0.13, 0.29)\n",
      "Vetor: tensor([0.1318, 0.2926, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        1.0000, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "def get_clevr_data_expanded(n_samples=100):\n",
    "    \"\"\"\n",
    "    Gera um dataset CLEVR sintético estendido para regras complexas.\n",
    "    Retorna tensor de formato (n_samples, 11).\n",
    "    \n",
    "    ESTRUTURA DO VETOR [11 features]:\n",
    "    -------------------------------------------------\n",
    "    [0, 1]    : Posição x, y (0.0 a 1.0)\n",
    "    [2, 3, 4] : Cores One-Hot (Vermelho, Verde, Azul)\n",
    "    [5, 6, 7, 8, 9] : Formas One-Hot (Círculo, Quadrado, Cilindro, Cone, Triângulo)\n",
    "    [10]      : Tamanho (0.0 = Pequeno, 1.0 = Grande)\n",
    "    -------------------------------------------------\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    # Mapeamento para labels legíveis\n",
    "    shapes_names = [\"Circle\", \"Square\", \"Cylinder\", \"Cone\", \"Triangle\"]\n",
    "    colors_names = [\"Red\", \"Green\", \"Blue\"]\n",
    "    sizes_names  = [\"Small\", \"Large\"]\n",
    "    \n",
    "    for _ in range(n_samples):\n",
    "        # 1. Posição (x, y)\n",
    "        x = np.random.rand()\n",
    "        y = np.random.rand()\n",
    "        \n",
    "        # 2. Cor (One-hot 3 cores)\n",
    "        color_idx = np.random.randint(0, 3)\n",
    "        color_vec = [0.0] * 3\n",
    "        color_vec[color_idx] = 1.0\n",
    "        \n",
    "        # 3. Forma (One-hot 5 formas)\n",
    "        shape_idx = np.random.randint(0, 5)\n",
    "        shape_vec = [0.0] * 5\n",
    "        shape_vec[shape_idx] = 1.0\n",
    "        \n",
    "        # 4. Tamanho (Binário com ruído leve para realismo)\n",
    "        # Se < 0.5 é Pequeno, se > 0.5 é Grande\n",
    "        is_large = np.random.rand() > 0.5\n",
    "        size_val = 1.0 if is_large else 0.0\n",
    "        \n",
    "        # Construção do Vetor\n",
    "        # [x, y] + [r, g, b] + [s1...s5] + [size]\n",
    "        vector = [x, y] + color_vec + shape_vec + [size_val]\n",
    "        data.append(vector)\n",
    "        \n",
    "        # Label para debug\n",
    "        desc = f\"{sizes_names[int(size_val)]} {colors_names[color_idx]} {shapes_names[shape_idx]} at ({x:.2f}, {y:.2f})\"\n",
    "        labels.append(desc)\n",
    "        \n",
    "    tensor_data = torch.tensor(data, dtype=torch.float32)\n",
    "    return tensor_data, labels\n",
    "\n",
    "# --- USO ---\n",
    "# Gerar dados\n",
    "data, texts = get_clevr_data_expanded(150)\n",
    "objects = ltn.Variable(\"objects\", data)\n",
    "\n",
    "print(f\"Dataset gerado. Shape: {data.shape}\")\n",
    "print(f\"Exemplo: {texts[0]}\")\n",
    "print(f\"Vetor: {data[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26ad48e2-71cc-494c-a5af-7b27af187175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset gerado com sucesso! Formato: torch.Size([50, 6])\n",
      "Exemplo de um objeto (x, y, r, g, b, s):\n",
      "tensor([0.0489, 0.1118, 0.0000, 0.0000, 1.0000, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "# --- Exemplo de Uso para os Alunos ---\n",
    "\n",
    "# Gerar 50 objetos\n",
    "objects_data = get_clevr_data(50)\n",
    "\n",
    "# Criar a variável LTN (que representa \"todos os objetos\")\n",
    "objects = ltn.Variable(\"objects\", objects_data)\n",
    "\n",
    "print(f\"Dataset gerado com sucesso! Formato: {objects_data.shape}\")\n",
    "print(\"Exemplo de um objeto (x, y, r, g, b, s):\")\n",
    "print(objects_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "17b642bc-c358-4186-9569-46ea2b5164dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Configure LTNtorch to use the appropriate device\n",
    "ltn.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {ltn.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2227af97-e0a6-4f70-918c-7e8001cf5b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. DEFINE LOGICAL CONNECTIVES AND QUANTIFIERS (REQUIRED IN LTNTORCH)\n",
    "Not = ltn.Connective(ltn.fuzzy_ops.NotStandard())\n",
    "And = ltn.Connective(ltn.fuzzy_ops.AndProd())\n",
    "Or = ltn.Connective(ltn.fuzzy_ops.OrProbSum())\n",
    "Implies = ltn.Connective(ltn.fuzzy_ops.ImpliesReichenbach())\n",
    "Forall = ltn.Quantifier(ltn.fuzzy_ops.AggregPMeanError(p=2), quantifier=\"f\")\n",
    "Exists = ltn.Quantifier(ltn.fuzzy_ops.AggregPMean(p=2), quantifier=\"e\")\n",
    "sat_agg = ltn.fuzzy_ops.SatAgg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4503ddf4-6cea-42ae-98dc-0240b8aa8eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. CREATE LTN OBJECTS (Constants and Variables)\n",
    "# Constants represent specific objects/entities\n",
    "# Variables represent quantifiable sets of objects\n",
    "\n",
    "# Example constants (specific objects)\n",
    "red_ball = ltn.Constant(torch.tensor([1.0, 0.0, 0.0]), trainable=False)  # RGB color vector\n",
    "blue_cube = ltn.Constant(torch.tensor([0.0, 0.0, 1.0]), trainable=False)  # RGB color vector\n",
    "\n",
    "# Example variables (sets of objects)\n",
    "balls = ltn.Variable(\"balls\", torch.tensor([\n",
    "    [1.0, 0.0, 0.0],  # red ball\n",
    "    [0.0, 1.0, 0.0],  # green ball  \n",
    "    [0.5, 0.0, 0.5],  # purple ball\n",
    "]))\n",
    "\n",
    "cubes = ltn.Variable(\"cubes\", torch.tensor([\n",
    "    [0.0, 0.0, 1.0],  # blue cube\n",
    "    [1.0, 1.0, 0.0],  # yellow cube\n",
    "    [0.5, 0.5, 0.5],  # gray cube\n",
    "]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "483900a0-5c7e-4d45-825b-f6d49710f02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. DEFINE PREDICATES (Logical properties/relations)\n",
    "class ColorPredicate(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(3, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 1),\n",
    "            nn.Sigmoid()  # Ensure output in [0,1] range\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Handle LTNObject inputs\n",
    "        if hasattr(x, 'value'):\n",
    "            x = x.value\n",
    "        return self.network(x).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5151e98a-4083-40bc-9431-f4c9b4baa71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create predicates\n",
    "is_red = ltn.Predicate(ColorPredicate())\n",
    "is_blue = ltn.Predicate(ColorPredicate())\n",
    "is_round = ltn.Predicate(ColorPredicate())  # Simplified example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97fadc75-6b1e-44d3-a3bd-6f0eacf33b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. DEFINE LOGICAL AXIOMS (Knowledge base)\n",
    "def axioms():\n",
    "    # Basic facts about specific objects\n",
    "    facts = [\n",
    "        is_red(red_ball),           # The red ball is red\n",
    "        is_blue(blue_cube),         # The blue cube is blue\n",
    "        is_round(red_ball),         # The red ball is round\n",
    "        Not(is_round(blue_cube))    # The blue cube is not round\n",
    "    ]\n",
    "    \n",
    "    # General rules about categories\n",
    "    rules = [\n",
    "        # All balls are round\n",
    "        Forall(balls, is_round(balls)),\n",
    "        \n",
    "        # If something is red, then it's likely to be a ball (simplified rule)\n",
    "        Forall(ltn.Variable(\"x\", torch.randn(10, 3, device=ltn.device)), \n",
    "               Implies(is_red(ltn.Variable(\"x\", torch.randn(10, 3, device=ltn.device))), \n",
    "                      is_round(ltn.Variable(\"x\", torch.randn(10, 3, device=ltn.device)))))\n",
    "    ]\n",
    "    \n",
    "    # Combine all axioms using And\n",
    "    all_axioms = facts + rules\n",
    "    return sat_agg(*all_axioms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2dd2db7-8fc9-4103-bd4a-f4677b54c169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. SATISFIABILITY CHECKING (Reasoning)\n",
    "def check_satisfiability():\n",
    "    # Get the satisfaction level of our knowledge base\n",
    "    sat_level = axioms()\n",
    "    print(f\"Knowledge base satisfaction level: {sat_level.item():.4f}\")\n",
    "    \n",
    "    return sat_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7471ec76-a43f-42c5-bc38-56ecc28c5883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. TRAINING THE PREDICATES (Learning from data)\n",
    "def train_predicates(epochs=100):\n",
    "    # Collect all parameters from predicates\n",
    "    parameters = list(is_red.model.parameters()) + \\\n",
    "                 list(is_blue.model.parameters()) + \\\n",
    "                 list(is_round.model.parameters())\n",
    "    \n",
    "    optimizer = torch.optim.Adam(parameters, lr=0.01)\n",
    "    \n",
    "    print(\"\\n=== TRAINING PREDICATES ===\")\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Get satisfaction loss (1 - satisfaction)\n",
    "        sat_loss = 1 - axioms()\n",
    "        \n",
    "        # Backpropagate\n",
    "        sat_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch % 20 == 0:\n",
    "            print(f\"Epoch {epoch}: Satisfaction = {1-sat_loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9196dbb6-77ad-4cf9-8312-c9465b196ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. QUERYING THE KNOWLEDGE BASE (Inference)\n",
    "def query_knowledge_base():\n",
    "    print(\"\\n=== QUERYING KNOWLEDGE BASE ===\")\n",
    "    \n",
    "    # Query 1: Is the red ball red?\n",
    "    query1 = is_red(red_ball)\n",
    "    print(f\"Q1: Is the red ball red? A: {query1.value.item():.4f}\")\n",
    "    \n",
    "    # Query 2: Is the blue cube round?\n",
    "    query2 = is_round(blue_cube)\n",
    "    print(f\"Q2: Is the blue cube round? A: {query2.value.item():.4f}\")\n",
    "    \n",
    "    # Query 3: Are all balls round? (Universal quantification)\n",
    "    all_balls_round = Forall(balls, is_round(balls))\n",
    "    print(f\"Q3: Are all balls round? A: {all_balls_round.value.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5e0d884e-87b9-409a-bf22-ce4cfddf1e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LTN LOGICAL REASONING EXAMPLE ===\n",
      "Knowledge base satisfaction level: 0.9519\n",
      "\n",
      "=== TRAINING PREDICATES ===\n",
      "Epoch 0: Satisfaction = 0.9372\n",
      "Epoch 20: Satisfaction = 0.9752\n",
      "Epoch 40: Satisfaction = 0.9151\n",
      "Epoch 60: Satisfaction = 0.9356\n",
      "Epoch 80: Satisfaction = 0.9858\n",
      "Knowledge base satisfaction level: 0.9835\n",
      "\n",
      "=== QUERYING KNOWLEDGE BASE ===\n",
      "Q1: Is the red ball red? A: 0.9735\n",
      "Q2: Is the blue cube round? A: 0.0300\n",
      "Q3: Are all balls round? A: 0.9960\n",
      "\n",
      "=== KEY INSIGHTS ABOUT LTNObjects ===\n",
      "1. LTNObjects wrap tensors with logical meaning\n",
      "2. Constants represent specific entities\n",
      "3. Variables represent quantifiable sets\n",
      "4. Predicates map LTNObjects to truth values [0,1]\n",
      "5. Logical connectives (And, Or, Not, Implies) work on truth values\n",
      "6. Quantifiers (Forall, Exists) aggregate over variables\n",
      "7. In LTNTorch, you must explicitly define all logical connectives\n",
      "8. The SatAgg function combines multiple axioms into a single satisfaction score\n"
     ]
    }
   ],
   "source": [
    "# 8. RUN THE COMPLETE EXAMPLE\n",
    "print(\"=== LTN LOGICAL REASONING EXAMPLE ===\")\n",
    "\n",
    "# Check initial satisfiability\n",
    "initial_sat = check_satisfiability()\n",
    "\n",
    "# Train the predicates to better satisfy our axioms\n",
    "train_predicates(epochs=100)\n",
    "\n",
    "# Check final satisfiability after training\n",
    "final_sat = check_satisfiability()\n",
    "\n",
    "# Query the trained knowledge base\n",
    "query_knowledge_base()\n",
    "\n",
    "print(\"\\n=== KEY INSIGHTS ABOUT LTNObjects ===\")\n",
    "print(\"1. LTNObjects wrap tensors with logical meaning\")\n",
    "print(\"2. Constants represent specific entities\")\n",
    "print(\"3. Variables represent quantifiable sets\")\n",
    "print(\"4. Predicates map LTNObjects to truth values [0,1]\")\n",
    "print(\"5. Logical connectives (And, Or, Not, Implies) work on truth values\")\n",
    "print(\"6. Quantifiers (Forall, Exists) aggregate over variables\")\n",
    "print(\"7. In LTNTorch, you must explicitly define all logical connectives\")\n",
    "print(\"8. The SatAgg function combines multiple axioms into a single satisfaction score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a7a950-8079-4168-8bce-03f5fc9bea69",
   "metadata": {},
   "source": [
    "## Setup for Equality Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8869b167-5276-48ba-95f8-25ab14409979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "EXTENSION: DIFFERENT FORMS OF EQUALITY IN LTN\n",
      "==================================================\n",
      "Equality experiment setup complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"EXTENSION: DIFFERENT FORMS OF EQUALITY IN LTN\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Define logical connectives for equality experiments\n",
    "Not_eq = ltn.Connective(ltn.fuzzy_ops.NotStandard())\n",
    "And_eq = ltn.Connective(ltn.fuzzy_ops.AndProd())\n",
    "Or_eq = ltn.Connective(ltn.fuzzy_ops.OrProbSum())\n",
    "Implies_eq = ltn.Connective(ltn.fuzzy_ops.ImpliesReichenbach())\n",
    "Forall_eq = ltn.Quantifier(ltn.fuzzy_ops.AggregPMeanError(p=2), quantifier=\"f\")\n",
    "Exists_eq = ltn.Quantifier(ltn.fuzzy_ops.AggregPMean(p=2), quantifier=\"e\")\n",
    "sat_agg_eq = ltn.fuzzy_ops.SatAgg()\n",
    "\n",
    "# Create sample data for equality experiments\n",
    "# Two objects that should be considered equal (same color)\n",
    "red_object1 = ltn.Constant(torch.tensor([1.0, 0.0, 0.0], device=ltn.device), trainable=True)\n",
    "red_object2 = ltn.Constant(torch.tensor([0.95, 0.05, 0.0], device=ltn.device), trainable=True)\n",
    "\n",
    "# Two objects that should be considered different\n",
    "blue_object = ltn.Constant(torch.tensor([0.0, 0.0, 1.0], device=ltn.device), trainable=True)\n",
    "\n",
    "# Variables for quantification\n",
    "objects = ltn.Variable(\"objects\", torch.tensor([\n",
    "    [1.0, 0.0, 0.0],    # red\n",
    "    [0.95, 0.05, 0.0],  # similar red  \n",
    "    [0.0, 0.0, 1.0],    # blue\n",
    "    [0.0, 1.0, 0.0],    # green\n",
    "], device=ltn.device))\n",
    "\n",
    "print(\"Equality experiment setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc7d2c2-028d-4dc3-95c8-c76fbc4795e5",
   "metadata": {},
   "source": [
    "## 1 LTN Diagonal Equality Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a5de92b8-0c3c-4f5f-ad13-66d204656a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------\n",
      "1. LTN DIAGONAL EQUALITY\n",
      "------------------------------\n",
      "Testing Diagonal Equality...\n",
      "Diagonal Equality KB Satisfaction: 0.7764\n",
      "Q: Are the two red objects equal? A: 0.9993\n",
      "Q: Is red object equal to blue object? A: 0.5000\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"-\"*30)\n",
    "print(\"1. LTN DIAGONAL EQUALITY\")\n",
    "print(\"-\"*30)\n",
    "\n",
    "class DiagonalEquality(nn.Module):\n",
    "    \"\"\"Implements diagonal equality using LTN's diag function\"\"\"\n",
    "    def forward(self, x, y):\n",
    "        # Handle LTNObject inputs\n",
    "        x_val = x.value if hasattr(x, 'value') else x\n",
    "        y_val = y.value if hasattr(y, 'value') else y\n",
    "        \n",
    "        # Create diagonal pairs and compute similarity\n",
    "        # For simplicity, we use cosine similarity on the diagonal\n",
    "        cos_sim = torch.nn.functional.cosine_similarity(x_val, y_val, dim=-1)\n",
    "        return 0.5 * (cos_sim + 1.0)  # Normalize to [0,1]\n",
    "\n",
    "# Create diagonal equality predicate\n",
    "Equal_Diag = ltn.Predicate(DiagonalEquality().to(ltn.device))\n",
    "\n",
    "def axioms_withEquality_Diag():\n",
    "    \"\"\"Knowledge base using diagonal equality\"\"\"\n",
    "    # Basic equality axioms\n",
    "    axioms = [\n",
    "        # Reflexivity: every object should be equal to itself\n",
    "        Forall_eq(objects, Equal_Diag(objects, objects)),\n",
    "        \n",
    "        # Symmetry example: if object1 equals object2, then object2 equals object1\n",
    "        Equal_Diag(red_object1, red_object2),\n",
    "        Equal_Diag(red_object2, red_object1),\n",
    "        \n",
    "        # Transitivity example (simplified)\n",
    "        Implies_eq(\n",
    "            And_eq(Equal_Diag(red_object1, red_object2), Equal_Diag(red_object2, red_object1)),\n",
    "            Equal_Diag(red_object1, red_object1)\n",
    "        ),\n",
    "        \n",
    "        # Different objects should not be equal\n",
    "        Not_eq(Equal_Diag(red_object1, blue_object))\n",
    "    ]\n",
    "    \n",
    "    return sat_agg_eq(*axioms)\n",
    "\n",
    "# Test diagonal equality\n",
    "print(\"Testing Diagonal Equality...\")\n",
    "sat_diag = axioms_withEquality_Diag()\n",
    "print(f\"Diagonal Equality KB Satisfaction: {sat_diag.item():.4f}\")\n",
    "\n",
    "# Query specific equalities\n",
    "query1 = Equal_Diag(red_object1, red_object2)\n",
    "query2 = Equal_Diag(red_object1, blue_object)\n",
    "print(f\"Q: Are the two red objects equal? A: {query1.value.item():.4f}\")\n",
    "print(f\"Q: Is red object equal to blue object? A: {query2.value.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e108fab-46aa-4267-918e-35aa319f44bd",
   "metadata": {},
   "source": [
    "## 2 - Cosine Equality Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "90dafd43-b0f2-4432-b76a-b65e3107e6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CosineEquality(nn.Module):\n",
    "    \"\"\"Implements cosine similarity-based equality with learnable temperature parameter\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Learnable temperature parameter to control sharpness of similarity\n",
    "        self.temperature = nn.Parameter(torch.tensor(1.0, device=ltn.device))\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        # Handle LTNObject inputs\n",
    "        x_val = x.value if hasattr(x, 'value') else x\n",
    "        y_val = y.value if hasattr(y, 'value') else y\n",
    "        \n",
    "        # Compute cosine similarity\n",
    "        cos_sim = torch.nn.functional.cosine_similarity(x_val, y_val, dim=-1)\n",
    "        \n",
    "        # Apply temperature scaling and normalize to [0,1] range\n",
    "        scaled_sim = torch.sigmoid(self.temperature * (cos_sim + 1.0) / 2.0)\n",
    "        return scaled_sim\n",
    "\n",
    "# Create cosine equality predicate\n",
    "Equal_Cos = ltn.Predicate(CosineEquality().to(ltn.device))\n",
    "\n",
    "def axioms_withEquality_Cos():\n",
    "    \"\"\"Knowledge base using cosine equality\"\"\"\n",
    "    # Get learnable parameters (now includes temperature)\n",
    "    parameters = list(Equal_Cos.model.parameters())\n",
    "    optimizer = torch.optim.Adam(parameters, lr=0.1)  # Higher LR for temperature\n",
    "    \n",
    "    print(\"Training Cosine Equality...\")\n",
    "    for epoch in range(200):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Same axioms as diagonal equality but with cosine predicate\n",
    "        axioms = [\n",
    "            Forall_eq(objects, Equal_Cos(objects, objects)),  # Reflexivity\n",
    "            Equal_Cos(red_object1, red_object2),               # Similar reds should be equal\n",
    "            Equal_Cos(red_object2, red_object1),               # Symmetry\n",
    "            Not_eq(Equal_Cos(red_object1, blue_object))        # Different colors not equal\n",
    "        ]\n",
    "        \n",
    "        sat = sat_agg_eq(*axioms)\n",
    "        loss = 1 - sat\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch % 50 == 0:\n",
    "            print(f\"Epoch {epoch}: Cosine Equality Satisfaction = {sat.item():.4f}, Temp = {Equal_Cos.model.temperature.item():.4f}\")\n",
    "    \n",
    "    # Return final satisfaction\n",
    "    final_axioms = [\n",
    "        Forall_eq(objects, Equal_Cos(objects, objects)),\n",
    "        Equal_Cos(red_object1, red_object2),\n",
    "        Not_eq(Equal_Cos(red_object1, blue_object))\n",
    "    ]\n",
    "    return sat_agg_eq(*final_axioms)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2c1e33cd-a415-4b0b-a890-3823fb531f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------\n",
      "2. COSINE EQUALITY (FIXED)\n",
      "------------------------------\n",
      "Training Cosine Equality...\n",
      "Epoch 0: Cosine Equality Satisfaction = 0.6112, Temp = 1.1000\n",
      "Epoch 50: Cosine Equality Satisfaction = 0.6255, Temp = 1.5738\n",
      "Epoch 100: Cosine Equality Satisfaction = 0.6255, Temp = 1.5680\n",
      "Epoch 150: Cosine Equality Satisfaction = 0.6255, Temp = 1.5687\n",
      "Final Cosine Equality KB Satisfaction: 0.5793\n",
      "Q: Are the two red objects equal (cosine)? A: 0.8275\n",
      "Q: Is red object equal to blue object (cosine)? A: 0.6866\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"-\"*30)\n",
    "print(\"2. COSINE EQUALITY (FIXED)\")\n",
    "print(\"-\"*30)\n",
    "\n",
    "# Test cosine equality\n",
    "sat_cos = axioms_withEquality_Cos()\n",
    "print(f\"Final Cosine Equality KB Satisfaction: {sat_cos.item():.4f}\")\n",
    "\n",
    "# Query specific equalities\n",
    "query1 = Equal_Cos(red_object1, red_object2)\n",
    "query2 = Equal_Cos(red_object1, blue_object)\n",
    "print(f\"Q: Are the two red objects equal (cosine)? A: {query1.value.item():.4f}\")\n",
    "print(f\"Q: Is red object equal to blue object (cosine)? A: {query2.value.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b35e58-16d5-4e71-a401-c11f1660b29c",
   "metadata": {},
   "source": [
    "## 3 - Euclidean Equality Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ef40899b-4c17-431b-aca3-9ecc052ae931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------\n",
      "3. EUCLIDEAN EQUALITY (FIXED)\n",
      "------------------------------\n",
      "Training Euclidean Equality...\n",
      "Epoch 0: Euclidean Equality Satisfaction = 0.8160, Gamma = 0.6000\n",
      "Epoch 30: Euclidean Equality Satisfaction = 0.9903, Gamma = 2.2782\n",
      "Epoch 60: Euclidean Equality Satisfaction = 0.9905, Gamma = 2.4738\n",
      "Epoch 90: Euclidean Equality Satisfaction = 0.9905, Gamma = 2.4658\n",
      "Epoch 120: Euclidean Equality Satisfaction = 0.9905, Gamma = 2.4479\n",
      "Final Euclidean Equality KB Satisfaction: 0.9917\n",
      "Q: Are the two red objects equal (Euclidean)? A: 0.9879\n",
      "Q: Is red object equal to blue object (Euclidean)? A: 0.0076\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"-\"*30)\n",
    "print(\"3. EUCLIDEAN EQUALITY (FIXED)\")\n",
    "print(\"-\"*30)\n",
    "\n",
    "class EuclideanEquality(nn.Module):\n",
    "    \"\"\"Implements Euclidean distance-based equality with learnable gamma parameter\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Learnable gamma parameter for strictness\n",
    "        self.gamma = nn.Parameter(torch.tensor(0.5, device=ltn.device))\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        # Handle LTNObject inputs\n",
    "        x_val = x.value if hasattr(x, 'value') else x\n",
    "        y_val = y.value if hasattr(y, 'value') else y\n",
    "        \n",
    "        # Compute Euclidean distance\n",
    "        distance = torch.sum(torch.square(x_val - y_val), dim=-1)\n",
    "        \n",
    "        # Apply exponential decay with learnable gamma\n",
    "        similarity = torch.exp(-self.gamma * distance)\n",
    "        \n",
    "        return similarity\n",
    "\n",
    "# Create Euclidean equality predicate\n",
    "Equal_Eucl = ltn.Predicate(EuclideanEquality().to(ltn.device))\n",
    "\n",
    "def axioms_withEquality_Eucl():\n",
    "    \"\"\"Knowledge base using Euclidean equality\"\"\"\n",
    "    parameters = list(Equal_Eucl.model.parameters())\n",
    "    optimizer = torch.optim.Adam(parameters, lr=0.1)  # Higher LR for gamma\n",
    "    \n",
    "    print(\"Training Euclidean Equality...\")\n",
    "    for epoch in range(150):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        axioms = [\n",
    "            Forall_eq(objects, Equal_Eucl(objects, objects)),  # Reflexivity\n",
    "            Equal_Eucl(red_object1, red_object2),               # Similar objects\n",
    "            Equal_Eucl(red_object2, red_object1),               # Symmetry\n",
    "            Not_eq(Equal_Eucl(red_object1, blue_object))        # Different objects\n",
    "        ]\n",
    "        \n",
    "        sat = sat_agg_eq(*axioms)\n",
    "        loss = 1 - sat\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch % 30 == 0:\n",
    "            print(f\"Epoch {epoch}: Euclidean Equality Satisfaction = {sat.item():.4f}, Gamma = {Equal_Eucl.model.gamma.item():.4f}\")\n",
    "    \n",
    "    # Final evaluation\n",
    "    final_axioms = [\n",
    "        Forall_eq(objects, Equal_Eucl(objects, objects)),\n",
    "        Equal_Eucl(red_object1, red_object2),\n",
    "        Not_eq(Equal_Eucl(red_object1, blue_object))\n",
    "    ]\n",
    "    return sat_agg_eq(*final_axioms)\n",
    "\n",
    "# Test Euclidean equality\n",
    "sat_eucl = axioms_withEquality_Eucl()\n",
    "print(f\"Final Euclidean Equality KB Satisfaction: {sat_eucl.item():.4f}\")\n",
    "\n",
    "# Query specific equalities\n",
    "query1 = Equal_Eucl(red_object1, red_object2)\n",
    "query2 = Equal_Eucl(red_object1, blue_object)\n",
    "print(f\"Q: Are the two red objects equal (Euclidean)? A: {query1.value.item():.4f}\")\n",
    "print(f\"Q: Is red object equal to blue object (Euclidean)? A: {query2.value.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8a0a88-d9ab-45ee-850b-e63b2ad4ddb8",
   "metadata": {},
   "source": [
    "## 4 - Learnable Manifold Equality Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6f67bedd-c96c-423e-a4df-c17aaa09cee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------\n",
      "4. LEARNABLE MANIFOLD EQUALITY (FIXED)\n",
      "------------------------------\n",
      "Training Learnable Equality Network...\n",
      "Epoch 0: Learnable Equality Satisfaction = 0.5278\n",
      "Epoch 50: Learnable Equality Satisfaction = 0.7959\n",
      "Epoch 100: Learnable Equality Satisfaction = 0.7959\n",
      "Epoch 150: Learnable Equality Satisfaction = 0.7959\n",
      "Epoch 200: Learnable Equality Satisfaction = 0.7959\n",
      "Epoch 250: Learnable Equality Satisfaction = 0.7959\n",
      "Final Learnable Equality KB Satisfaction: 0.7113\n",
      "Q: Are the two red objects equal (Learned)? A: 1.0000\n",
      "Q: Is red object equal to blue object (Learned)? A: 0.0002\n",
      "Q: Is red object equal to itself (Learned)? A: 1.0000\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"-\"*30)\n",
    "print(\"4. LEARNABLE MANIFOLD EQUALITY (FIXED)\")\n",
    "print(\"-\"*30)\n",
    "\n",
    "class LearnableEquality(nn.Module):\n",
    "    \"\"\"Implements learnable equality using neural network\"\"\"\n",
    "    def __init__(self, input_dim=3):\n",
    "        super(LearnableEquality, self).__init__()\n",
    "        # Input dim is 2 * feature_dim because of concatenation\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim * 2, 64),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()  # Critical: output must be in [0,1]\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        # Handle LTNObject inputs\n",
    "        x_val = x.value if hasattr(x, 'value') else x\n",
    "        y_val = y.value if hasattr(y, 'value') else y\n",
    "        \n",
    "        # Concatenate along the feature dimension\n",
    "        cat_inputs = torch.cat([x_val, y_val], dim=-1)\n",
    "        return self.net(cat_inputs).squeeze()\n",
    "\n",
    "# Create learnable equality predicate\n",
    "Equal_Learned = ltn.Predicate(LearnableEquality(input_dim=3).to(ltn.device))\n",
    "\n",
    "def axioms_withEquality_Learned():\n",
    "    \"\"\"Knowledge base using learnable manifold equality\"\"\"\n",
    "    parameters = list(Equal_Learned.model.parameters())\n",
    "    optimizer = torch.optim.Adam(parameters, lr=0.01)\n",
    "    \n",
    "    print(\"Training Learnable Equality Network...\")\n",
    "    for epoch in range(300):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Complex equality axioms that require learning\n",
    "        axioms = [\n",
    "            # Reflexivity: every object equals itself\n",
    "            Forall_eq(objects, Equal_Learned(objects, objects)),\n",
    "            \n",
    "            # Similar objects should be equal (red objects)\n",
    "            Equal_Learned(red_object1, red_object2),\n",
    "            Equal_Learned(red_object2, red_object1),\n",
    "            \n",
    "            # Different objects should not be equal\n",
    "            Not_eq(Equal_Learned(red_object1, blue_object)),\n",
    "            Not_eq(Equal_Learned(blue_object, red_object1)),\n",
    "            \n",
    "            # Transitivity example (if A=B and B=C then A=C)\n",
    "            Implies_eq(\n",
    "                And_eq(Equal_Learned(red_object1, red_object2), Equal_Learned(red_object2, red_object1)),\n",
    "                Equal_Learned(red_object1, red_object1)\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        sat = sat_agg_eq(*axioms)\n",
    "        loss = 1 - sat\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch % 50 == 0:\n",
    "            print(f\"Epoch {epoch}: Learnable Equality Satisfaction = {sat.item():.4f}\")\n",
    "    \n",
    "    # Final evaluation with more complex queries\n",
    "    final_axioms = [\n",
    "        Forall_eq(objects, Equal_Learned(objects, objects)),\n",
    "        Equal_Learned(red_object1, red_object2),\n",
    "        Not_eq(Equal_Learned(red_object1, blue_object))\n",
    "    ]\n",
    "    return sat_agg_eq(*final_axioms)\n",
    "\n",
    "# Test learnable equality\n",
    "sat_learned = axioms_withEquality_Learned()\n",
    "print(f\"Final Learnable Equality KB Satisfaction: {sat_learned.item():.4f}\")\n",
    "\n",
    "# Query specific equalities\n",
    "query1 = Equal_Learned(red_object1, red_object2)\n",
    "query2 = Equal_Learned(red_object1, blue_object)\n",
    "query3 = Equal_Learned(red_object1, red_object1)  # Reflexivity check\n",
    "\n",
    "print(f\"Q: Are the two red objects equal (Learned)? A: {query1.value.item():.4f}\")\n",
    "print(f\"Q: Is red object equal to blue object (Learned)? A: {query2.value.item():.4f}\")\n",
    "print(f\"Q: Is red object equal to itself (Learned)? A: {query3.value.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b654ab4-d5aa-4fa7-ba7a-0f041d630f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6269, 0.7298, 1.0000, 0.0000, 0.0000, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "print(objects_data[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e3f2f5-525e-446f-ae19-68022ca88c4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
